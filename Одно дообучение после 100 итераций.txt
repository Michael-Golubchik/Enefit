09.01.2024
Поправил производные параметры после добавления лагов 7-13
Взял такие же параметры как в пашином лучшем ноутбуке и его же гиперпараметры

(ALL)	(> 600)	(> 600, is_cons==0)	(> 600, is_cons==1)
MAE	49.074	54.196	63.638	44.754

-------------------------
Разделил на четные нечетные дни обучение

(ALL)	(> 600)	(> 600, is_cons==0)	(> 600, is_cons==1)
MAE	49.128	54.603	63.789	45.417

08.01.2024

Обучение раз в 2 дня, по пять раздельных моделей, по пять моделей на всем датасете

(ALL)	(> 600)	(> 600, is_cons==0)	(> 600, is_cons==1)
MAE	49.438	54.946	64.418	45.473

Одна итерация с обучением 498 сек
Без обучения после 600 - 15 сек
Без обучения до 600 - 4 сек

Wall time: 2h 59min 17s

-----------------

Обучение раз в 2 дня, два ансамбля (стандартных) по пять моделей на всем датасете

(ALL)	(> 600)	(> 600, is_cons==0)	(> 600, is_cons==1)
MAE	49.233	54.871	64.295	45.447

Одна итерация с обучением 544 сек
Без обучения после 600 - 17 сек
Без обучения до 600 - 4 сек

Wall time: 3h 1min 41s

------------
Обучение раз в 7 дней по одной модели на всем датасете, но предсказание вначале
MAE: 52.37592635706152
MAE после 600: 61.92363407830839
Одна итерация с обучением 77 сек
Без обучения после 600 - 10 сек
Без обучения до 600 - 3 сек

--------

Обучение раз в 7 дней по одной модели на [[0,90],[305,120]] 
MAE: 55.06780035323453
MAE после 600: 65.85206385532219

Одна итерация с обучением 48 сек
Без обучения после 600 - 10 сек
Без обучения до 600 - 2 - 3 сек

Wall time: 14min 7s
-------------------

Обучение раз в 7 дней по одной модели на всем датасете

MAE: 52.45918278481437
MAE после 600: 61.53087923286491

Одна итерация с обучением 80 сек
Без обучения после 600 - 10 сек
Без обучения до 600 - 2 - 3 сек

Wall time: 17min 30s
-------------------
Обучение раз в 7 дней по одной модели последний месяц и в прошлом году на два месяцв вперед и на один назад

MAE: 57.539836829170525
MAE после 600: 68.70247829298258

Одна итерация с обучением 39 сек
Без обучения после 600 - 10 сек
Без обучения до 600 - 2 - 3 сек

Wall time: 13min 38s

----------------------

Обучение раз в 7 дней по одной модели последние 3 месяца
MAE: 68.94841734636259
MAE после 600: 74.18531535465755

Одна итерация с обучением 27 сек
Без обучения после 600 - 10 сек
Без обучения до 600 - 2 сек

Wall time: 13min 5s

------------
Обучение раз в 7 дней по одной модели от начала 2022
MAE: 53.070358380167136
MAE после 600: 61.65171883157607
Одна итерация с обучением 70 сек
Без обучения после 600 - 10 сек
Без обучения до 600 - 3 сек

Wall time: 16min 30s

02.01.2024

На процессоре 7 LGB, на GPU 7 catboost
big-voting

MAE: 50.35343756121635
MAE после 600: 57.853504827288035

Wall time: 2h 15min 29s

-----------------------------

На GPU 7 LGB, на GPU 7 catboost
big-voting

MAE: 51.22385763876956
MAE после 600: 58.32761690880653


Wall time: 1h 44min 56s

01.01.2024

Обучение на одной модели LGB. каждая иттерация

MAE: 51.23273981583022
MAE после 600: 58.12265381520637


Один LGB учится на всем датасете 46.5 s

На реальном сабмите работало 4 часа. И дало скор 67.73

Один катбуст столько учится на всем датасете в колабе
CPU times: user 11min 3s, sys: 23.8 s, total: 11min 26s
Wall time: 5min 24s

30.12.2023

Обучение на одной модели LGB
p_day={'device_type': 'gpu', 'learning_rate': 0.050239193018201116, 'colsample_bytree': 0.7523230869476827, 'colsample_bynode': 0.8016401710184272, 'lambda_l1': 0.804941519994492, 'lambda_l2': 5.420391522845777, 'min_data_in_leaf': 53, 'max_depth': 15, 'max_bin': 250, 'n_estimators': 1367, 'num_leaves': 75, 'feature_fraction': 0.7660656830160648, 'bagging_fraction': 0.8829219702163389, 'bagging_freq': 1}

MAE: 52.46774520243032
MAE после 600: 57.81252050963999
-------------

Обучение LGB,Catboost,Ансамбль, раз в 10 итераций.
Модели начали обучатся заново после сотой итерации

MAE: 51.456707274921
MAE после 600: 59.441935951172255

Wall time: 1h 2min 35s

--------------------

MAE: 48.90488667113105
MAE после 600: 60.127042776797076

Обучение каждую иттерацию

Wall time: 1h 49min 46s

Одно дообучение после 100 итераций
-------
C солнечной и catboost
MAE: 52.665883384091615
MAE после 600: 64.80163272911258

Без предсказания отдельно солнечной и без catboost

MAE: 53.559672068932294
MAE после 600: 64.26519776056288
Wall time: 10min 22s

Другие гиперпараметры
MAE: 54.38975549394602
MAE после 600: 64.97409773597747
Wall time: 10min 33s


--------
C солнечной и без catboost

MAE: 53.55310074056287
MAE после 600: 65.4516293965151

Wall time: 13min 11s

-----------
Без Ансамбля на одном LGB
MAE: 55.25787206426289
MAE после 600: 65.89579792539683


Ансамбль из пяти LGBB  учится 2 мин 45с
Один LGB  учится 31с

--------------
Старое

CPU times: total: 27min 2s
Wall time: 10min 31s

499:	learn: 13.1653175	total: 2m 48s	remaining: 0us
CPU times: total: 4min 18s
Wall time: 9min 40s



df_test = df_train[df_train["data_block_id"] > 500]
df_train = df_train[df_train["data_block_id"] <= 500]

MAE: 53.863493609135766
MAE после 600: 72.0904233793189

-------------------------------------

df_test = df_train[df_train["data_block_id"] > 600]
df_train = df_train[df_train["data_block_id"] <= 600]

MAE после 600: 62.322612065155816

---------------

MAE: 53.85952043437875
CPU times: total: 1min 47s
Wall time: 38.9 s

MAE после 600: 72.06924064471146

------------------

MAE: 52.393873572779114
CPU times: total: 1min 57s
Wall time: 41.4 s

MAE после 600: 70.12715495253079

MAE: 48.90488667113105
MAE после 600: 60.127042776797076